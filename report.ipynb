{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "GnvMrxg6Tf0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "from itertools import product\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "-UYoay34TZaK"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "4njmIOyrvklD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data types\n",
        "const_dtype = { 'ano': int, 'uf': str, 'genero': str, 'mes': str, 'numero': int }"
      ],
      "metadata": {
        "id": "_4l-tRQeylqj"
      },
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "const_dict_month = {\n",
        "    'Janeiro': 1,   'Fevereiro': 2,   'Março': 3,       'Abril': 4,\n",
        "    'Maio': 5,      'Junho': 6,       'Julho': 7,       'Agosto': 8,\n",
        "    'Setembro': 9,  'Outubro': 10,    'Novembro': 11,   'Dezembro': 12\n",
        "}"
      ],
      "metadata": {
        "id": "bN9ZU_dcvmf5"
      },
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data"
      ],
      "metadata": {
        "id": "OKhjssDY5cSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_csv_files(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        content = response.json()\n",
        "        csv_files = [file['download_url'] for file in content if file['name'].endswith('.csv')]\n",
        "        return csv_files\n",
        "    else:\n",
        "        print(f'Error accessing URL.\\nStatus code: {response.status_code}')"
      ],
      "metadata": {
        "id": "hrUy2G68Tjbq"
      },
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataframes(user, repo, folder, dtype=None):\n",
        "    url = f'https://api.github.com/repos/{user}/{repo}/contents/{folder}'\n",
        "    csv_files = list_csv_files(url)\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    for file_url in csv_files:\n",
        "        df = pd.read_csv(file_url, dtype=dtype)\n",
        "        df_list.append(df)\n",
        "\n",
        "    df_list = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "    return df_list"
      ],
      "metadata": {
        "id": "5VsLHjOgpmZr"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "U6sZY1zeNi8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eliminating irrelevant attributes"
      ],
      "metadata": {
        "id": "1Aq12ROFN4lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminate_columns(df, columns=[]):\n",
        "    # Drop columns\n",
        "    df = df.drop(columns=columns)\n",
        "    return df"
      ],
      "metadata": {
        "id": "vmBbdMTFN7Q5"
      },
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling attributes with missing values"
      ],
      "metadata": {
        "id": "Z_curvmzOOgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_rows_with_null_values(df):\n",
        "    # Indexes of rows with null values\n",
        "    idxNullRows = pd.isnull(df).any().to_numpy().nonzero()\n",
        "\n",
        "    return idxNullRows"
      ],
      "metadata": {
        "id": "6n8bGJapOZzf"
      },
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression model"
      ],
      "metadata": {
        "id": "CvwWO9v1jIb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparer"
      ],
      "metadata": {
        "id": "xPgeP8BSkPRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(df):\n",
        "    df = pd.get_dummies(df, columns=['genero'], drop_first=True)\n",
        "\n",
        "    # Add number of month\n",
        "    df['n_mes'] = df['mes'].map(const_dict_month)\n",
        "\n",
        "    # Column to represent time since the start data\n",
        "    df['tempo'] = (df['ano'] - df['ano'].min()) * 12 + df['n_mes']\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "tzvTqxg2uMw9"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_dataset(df, resources_columns, target_column=False):\n",
        "    # Define X using df and resource variables\n",
        "    X = df[resources_columns]\n",
        "\n",
        "    # Define Y using target variable\n",
        "    y = df[target_column] if target_column else None\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "PBCGBukTpzNp"
      },
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, y, test_size=0.3):\n",
        "    # Split dataset with the selected test_size or 70/30 by default\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=13)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "3_vR__KFpxiL"
      },
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model & predict"
      ],
      "metadata": {
        "id": "KUEMpw92lFWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(X_train, y_train):\n",
        "    # Create LinearRegression Model\n",
        "    model = LinearRegression()\n",
        "\n",
        "    # Compile model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "N09UyB1ulHj9"
      },
      "execution_count": 358,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, X):\n",
        "    y_pred = model.predict(X)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "VHu2kfaDnHbo"
      },
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "ZznBbto_nGGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summary_model(uf, X_train, X_test, y_train, y_test, y_pred):\n",
        "    mae = round(mean_absolute_error(y_test, y_pred), 4)\n",
        "    mse = round(mean_squared_error(y_test, y_pred), 4)\n",
        "\n",
        "    print(f'========== Model {uf} ==========')\n",
        "    print(f'\\nData Split (proportion {test_size}):')\n",
        "    print(f'\\tX_train: {X_train.shape} | y_train: {y_train.shape}')\n",
        "    print(f'\\tX_test: {X_test.shape} | y_test: {y_test.shape}')\n",
        "    print(f'\\nModel metrics:')\n",
        "    print(f'\\tErro Médio Absoluto (MAE): {mae}')\n",
        "    print('\\tO MAE indica a média da diferença entre o valor real com o predito\\n')\n",
        "    print(f'\\tErro Quadrático Médio (MSE): {mse}')\n",
        "    print('\\tO MSE indica a diferença real/previsto, porém acentuando diferenças maiores\\n\\n')"
      ],
      "metadata": {
        "id": "FLFfXrkwp2IA"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report utils"
      ],
      "metadata": {
        "id": "aSAiP5gcgnLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_previous_year(df):\n",
        "    return df['ano'].max()"
      ],
      "metadata": {
        "id": "NKLVJX6hgqi7"
      },
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_largests_ufs_by_year(df, year, n=3):\n",
        "    # Filter data os previous year\n",
        "    df_previous_year = df[df['ano'] == year]\n",
        "\n",
        "    # Group targert column using column uf\n",
        "    total_per_uf = df_previous_year.groupby('uf')['numero'].sum()\n",
        "\n",
        "    # Sort results and get top N\n",
        "    top_n_ufs = total_per_uf.nlargest(n)\n",
        "\n",
        "    # Format ufs in a list\n",
        "    top_n_ufs = list(top_n_ufs.to_dict().keys())\n",
        "\n",
        "    return top_n_ufs"
      ],
      "metadata": {
        "id": "gSDmbzzgg3kK"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit model"
      ],
      "metadata": {
        "id": "vc183TvzTtjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GitHub repository with the data\n",
        "user, repo, folder = 'GabrielNG13', 'ps-mediamonks-datascience', 'data/transient'\n",
        "\n",
        "# Loading data\n",
        "raw_df = get_dataframes(user, repo, folder, const_dtype)"
      ],
      "metadata": {
        "id": "WRao2mET5knC"
      },
      "execution_count": 363,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs_per_uf = raw_df.groupby('uf')\n",
        "models = {}\n",
        "\n",
        "for uf, df in dfs_per_uf:\n",
        "\n",
        "    # Drop uf column\n",
        "    df = eliminate_columns(df, columns=['uf'])\n",
        "\n",
        "    # No record has any null values\n",
        "    # No action necessary\n",
        "    rows = find_rows_with_null_values(df)\n",
        "\n",
        "    dataset = prepare_dataset(df)\n",
        "\n",
        "    # Set categorical and target columns\n",
        "    resources_columns = ['ano', 'tempo', 'n_mes'] + [ col for col in dataset.columns if 'genero' in col ]\n",
        "    target_column = 'numero'\n",
        "\n",
        "    X, y = define_dataset(dataset, resources_columns, target_column)\n",
        "\n",
        "    # Proportion test/total\n",
        "    test_size = 0.3\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X, y, test_size)\n",
        "\n",
        "    # Creating and training the regression model\n",
        "    modelo = LinearRegression()\n",
        "    modelo.fit(X, y)\n",
        "\n",
        "    # Create model\n",
        "    model = define_model(X_train, y_train)\n",
        "\n",
        "    # Results\n",
        "    y_pred = predict(model, X_test)\n",
        "    summary_model(uf, X_train, X_test, y_train, y_test, y_pred)\n",
        "\n",
        "    # Store trained model\n",
        "    models[uf] = model"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oCe0UtYq3fc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report"
      ],
      "metadata": {
        "id": "JcN_ivi3fg8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Previous year\n",
        "previous_year = get_previous_year(raw_df)\n",
        "\n",
        "# Get top 3 ufs\n",
        "top_3_ufs = get_largests_ufs_by_year(raw_df, previous_year, 3)"
      ],
      "metadata": {
        "id": "QeYc81iSfijk"
      },
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define years to predict data\n",
        "years = [str(int(previous_year) + 1), str(int(previous_year) + 2)]\n",
        "\n",
        "# Get genders and months list\n",
        "ufs = list(raw_df['uf'].unique())\n",
        "genders = list(raw_df['genero'].unique())\n",
        "months = list(raw_df['mes'].unique())\n",
        "\n",
        "# Generate DataFrame with combinations of year, uf, gender and month\n",
        "combinations = list(product(years, ufs, genders, months))\n",
        "\n",
        "# Create general DataFrame\n",
        "columns = ['ano', 'uf', 'genero', 'mes']\n",
        "df_predict = pd.DataFrame(combinations, columns=columns)\n",
        "df_predict['ano'] = df_predict['ano'].astype(int)"
      ],
      "metadata": {
        "id": "96sGVlgihhh3"
      },
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs_to_predict = df_predict.loc[df_predict['uf'].isin(top_3_ufs)].groupby('uf')\n",
        "predicts = {}\n",
        "\n",
        "for uf, df in dfs_to_predict:\n",
        "\n",
        "    # Drop uf column\n",
        "    df = eliminate_columns(df, columns=['uf'])\n",
        "\n",
        "    # No record has any null values\n",
        "    # No action necessary\n",
        "    rows = find_rows_with_null_values(df)\n",
        "\n",
        "    dataset = prepare_dataset(df)\n",
        "\n",
        "    # Set categorical columns\n",
        "    resources_columns = ['ano', 'tempo', 'n_mes'] + [ col for col in dataset.columns if 'genero' in col ]\n",
        "\n",
        "    X_predict, _ = define_dataset(dataset, resources_columns)\n",
        "    y_pred = predict(models[uf], X_predict)\n",
        "\n",
        "    predicts[uf] = y_pred"
      ],
      "metadata": {
        "id": "ni4B9QzL8ED1"
      },
      "execution_count": 381,
      "outputs": []
    }
  ]
}